# Universal LoRA

**Universal LoRA** is a lightweight, modular PyTorch library that enables the integration of **Low-Rank Adaptation (LoRA)** into common neural network layers. The library provides easy-to-use wrappers and utility functions to inject LoRA modules into any PyTorch model, including models from `timm`.

---

## ğŸ”§ Features

- ğŸ§© Drop-in LoRA wrappers for:
  - `nn.Linear`
  - `nn.Conv1d`, `nn.Conv2d`, `nn.Conv3d`
  - `nn.Embedding`
- ğŸ” Recursively inject LoRA layers using `apply_lora()`
- â„ï¸ Automatically freeze original layer weights
- ğŸ’¾ Save/load only the LoRA-specific parameters
- ğŸ§ª Includes PyTest-based test suite

---

## ğŸš€ Installation

```bash
git clone https://github.com/foiv0s/universal_lora.git
cd universal_lora
pip install -e .